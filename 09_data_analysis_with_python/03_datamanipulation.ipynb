{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Manipulation and Analysis with Pandas\n",
    "Data manipulation and analysis are key tasks in any data science or data analysis project. Pandas provides a wide range of functions for data manipulation and analysis, making it easier to clean, transform, and extract insights from data. In this lesson, we will cover various data manipulation and analysis techniques using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')\n",
    "## fecth the first 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling Missing Values\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Checking in which column missing values present\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many missing values in columns\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values with zeroes\n",
    "df_filled=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filling missing values with the mean of the column\n",
    "# This code correctly fills missing values in the \"Sales\" column with the mean of that column and stores the result in a new column called \"Sales_fillNA\"\n",
    "df['Sales_fillNA']=df['Sales'].fillna(df['Sales'].mean())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names the colums present\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming Columns\n",
    "# renames the column \"Sale Date\" to \"Sales Date\"\n",
    "df=df.rename(columns={'Date':'Sales Date'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change datatypes\n",
    "df['Value_new']=df['Value'].fillna(df['Value'].mean()).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['New Value']=df['Value'].apply(lambda x:x*2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Aggregating And Grouping\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_mean=df.groupby('Product')['Value'].mean()\n",
    "print(grouped_mean)\n",
    "\n",
    "'''\n",
    "The code groups a DataFrame by 'Product' and computes the mean of the 'Value' column for each group, returning a new series with product names as indices and average values as corresponding values.\n",
    "\n",
    "Grouping the Data:\n",
    "\n",
    "df.groupby('Product') tells Python to take your DataFrame (df) and split it into groups based on the unique values in the 'Product' column.\n",
    "For example, if your DataFrame has several products like \"A\", \"B\", and \"C\", this step will create three groups: one for each product.\n",
    "Selecting the 'Value' Column:\n",
    "\n",
    "After grouping, ['Value'] selects only the 'Value' column from each group.\n",
    "This means we're only interested in the numerical values from the 'Value' column for the calculations.\n",
    "Calculating the Mean:\n",
    "\n",
    ".mean() computes the average of the 'Value' column within each product group.\n",
    "For each product group, it adds up all the values in the 'Value' column and divides by the number of entries in that group.\n",
    "Storing the Result:\n",
    "\n",
    "The result is stored in the variable grouped_mean. This is typically a Series where:\n",
    "The index is the unique product names.\n",
    "The values are the calculated averages for each product.\n",
    "Printing the Result:\n",
    "\n",
    "print(grouped_mean) displays the average 'Value' for each product group on the screen.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sum=df.groupby(['Product','Region'])['Value'].sum()\n",
    "print(grouped_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Product','Region'])['Value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregate multiple functions\n",
    "groudped_agg=df.groupby('Region')['Value'].agg(['mean','sum','count'])\n",
    "groudped_agg\n",
    "\n",
    "'''\n",
    "\n",
    "Grouping the DataFrame by Region:\n",
    "\n",
    "df.groupby('Region') tells Python to split your DataFrame into groups based on the unique values in the 'Region' column.\n",
    "For example, if your DataFrame contains regions like \"North\", \"South\", \"East\", and \"West\", this command will create a group for each region.\n",
    "Selecting the 'Value' Column:\n",
    "\n",
    "['Value'] specifies that we only want to work with the 'Value' column from each group.\n",
    "This column is assumed to be numerical, which is important because we will be calculating statistics on it.\n",
    "Applying Multiple Aggregation Functions:\n",
    "\n",
    "The .agg(['mean', 'sum', 'count']) method tells Python to perform three different operations on the 'Value' column for each group:\n",
    "mean: Calculates the average value.\n",
    "sum: Adds up all the values.\n",
    "count: Counts the number of entries (rows) in each group.\n",
    "These functions are applied simultaneously, and the result is a new DataFrame that includes all three statistics for each region.\n",
    "Storing and Displaying the Result:\n",
    "\n",
    "The result is stored in the variable groudped_agg (note: thereâ€™s a small typo in the variable name; it likely should be grouped_agg).\n",
    "When you run groudped_agg (or print it), you will see a table where:\n",
    "The index consists of the unique regions.\n",
    "The columns are mean, sum, and count, each showing the corresponding calculation for the 'Value' column in that region.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merging and joining Dataframes\n",
    "# Create sample DataFrames\n",
    "df1 = pd.DataFrame({'Key': ['A', 'B', 'C'], 'Value1': [1, 2, 3]})\n",
    "df2 = pd.DataFrame({'Key': ['A', 'B', 'D'], 'Value2': [4, 5, 6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge Datafranme on the 'Key Columns'\n",
    "pd.merge(df1,df2,on=\"Key\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2,on=\"Key\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2,on=\"Key\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2,on=\"Key\",how=\"right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
